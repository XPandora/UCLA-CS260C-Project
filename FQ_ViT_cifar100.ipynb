{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FQ_ViT_cifar100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d3bdfa8165a42c18130b8b88f6e135f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b559b6298d7c438aa20e44607843ea74",
              "IPY_MODEL_a8aea74c327e4172b7484b12e01ec06c",
              "IPY_MODEL_c8bca9c208294b6b8daf6830d7d678bd"
            ],
            "layout": "IPY_MODEL_74174fed1b804d5fbf1aa271826f5f09"
          }
        },
        "b559b6298d7c438aa20e44607843ea74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db984f5361846e9b9a0b0146b788717",
            "placeholder": "​",
            "style": "IPY_MODEL_268eb293a26c45ef999d8dd65bd0f3d6",
            "value": ""
          }
        },
        "a8aea74c327e4172b7484b12e01ec06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4a569402d64105b13d0eafc9908cb5",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e885de69d23044ecb229f2be9dbd3a84",
            "value": 169001437
          }
        },
        "c8bca9c208294b6b8daf6830d7d678bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb23bf01c30340cabe9671fcacd58f41",
            "placeholder": "​",
            "style": "IPY_MODEL_10ceac87431d4f1e867379325d3ef5af",
            "value": " 169001984/? [00:05&lt;00:00, 32463668.37it/s]"
          }
        },
        "74174fed1b804d5fbf1aa271826f5f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db984f5361846e9b9a0b0146b788717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268eb293a26c45ef999d8dd65bd0f3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4a569402d64105b13d0eafc9908cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e885de69d23044ecb229f2be9dbd3a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb23bf01c30340cabe9671fcacd58f41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ceac87431d4f1e867379325d3ef5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIjX43sJni0_",
        "outputId": "ee6aeb5c-6dc9-4dd7-8a91-72f39f5eba0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FQ-ViT'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Total 52 (delta 0), reused 0 (delta 0), pack-reused 52\u001b[K\n",
            "Unpacking objects: 100% (52/52), done.\n",
            "/content/FQ-ViT\n",
            "--2022-03-15 05:49:23--  https://docs.google.com/uc?export=download&confirm=t&id=1ozBb5ynqQfchkNWccbO1qvGD-NRNK9SH\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.127.113, 108.177.127.138, 108.177.127.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.127.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-5g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kik4l3kcqvaalj7lonbbp2t9sunrp455/1647323325000/17691537378993098219/*/1ozBb5ynqQfchkNWccbO1qvGD-NRNK9SH?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-03-15 05:49:24--  https://doc-0o-5g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kik4l3kcqvaalj7lonbbp2t9sunrp455/1647323325000/17691537378993098219/*/1ozBb5ynqQfchkNWccbO1qvGD-NRNK9SH?e=download\n",
            "Resolving doc-0o-5g-docs.googleusercontent.com (doc-0o-5g-docs.googleusercontent.com)... 108.177.119.132, 2a00:1450:4013:c00::84\n",
            "Connecting to doc-0o-5g-docs.googleusercontent.com (doc-0o-5g-docs.googleusercontent.com)|108.177.119.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 343271761 (327M) [application/x-zip]\n",
            "Saving to: ‘converted_cifar10-100_500_checkpoint.bin’\n",
            "\n",
            "converted_cifar10-1 100%[===================>] 327.37M  33.3MB/s    in 10s     \n",
            "\n",
            "2022-03-15 05:49:34 (32.4 MB/s) - ‘converted_cifar10-100_500_checkpoint.bin’ saved [343271761/343271761]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/linyang-zhh/FQ-ViT.git\n",
        "%cd FQ-ViT\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ozBb5ynqQfchkNWccbO1qvGD-NRNK9SH' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1ozBb5ynqQfchkNWccbO1qvGD-NRNK9SH\" -O converted_cifar10-100_500_checkpoint.bin && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if running on a local divice, comment these lines\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3nxLXwPIBVH",
        "outputId": "a73a714d-5935-43d9-9e32-bebff24981d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "### Before running this code cell:\n",
        "### Add parameter num_classes=10 to the line 552 of models/vit_quant.py file\n",
        "###\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, RandomSampler, DistributedSampler, SequentialSampler\n",
        "\n",
        "from models import *\n",
        "from config import Config\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"FQ-ViT\")\n",
        "\n",
        "# parser.add_argument(\"model\",\n",
        "#                     choices=['deit_tiny', 'deit_small', 'deit_base', 'vit_base',\n",
        "#                              'vit_large', 'swin_tiny', 'swin_small', 'swin_base'],\n",
        "#                     help=\"model\")\n",
        "# parser.add_argument('data', metavar='DIR',\n",
        "#                     help='path to dataset')\n",
        "parser.add_argument(\"--quant\", default=False, action=\"store_true\")\n",
        "parser.add_argument(\"--pts\", default=False, action=\"store_true\")\n",
        "parser.add_argument(\"--lis\", default=False, action=\"store_true\")\n",
        "parser.add_argument(\"--quant-method\", default=\"minmax\",\n",
        "                    choices=[\"minmax\", \"ema\", \"omse\", \"percentile\"])\n",
        "parser.add_argument(\"--calib-batchsize\", default=100,\n",
        "                    type=int, help=\"batchsize of calibration set\")\n",
        "parser.add_argument(\"--calib-iter\", default=10, type=int)\n",
        "parser.add_argument(\"--val-batchsize\", default=100,\n",
        "                    type=int, help=\"batchsize of validation set\")\n",
        "parser.add_argument(\"--num-workers\", default=16, type=int,\n",
        "                    help=\"number of data loading workers (default: 16)\")\n",
        "parser.add_argument(\"--device\", default=\"cuda\", type=str, help=\"device\")\n",
        "parser.add_argument(\"--print-freq\", default=100,\n",
        "                    type=int, help=\"print frequency\")\n",
        "parser.add_argument(\"--seed\", default=0, type=int, help=\"seed\")\n",
        "\n",
        "\n",
        "def str2model(name):\n",
        "    d = {'deit_tiny': deit_tiny_patch16_224,\n",
        "         'deit_small': deit_small_patch16_224,\n",
        "         'deit_base': deit_base_patch16_224,\n",
        "         'vit_base': vit_base_patch16_224,\n",
        "         'vit_large': vit_large_patch16_224,\n",
        "         'swin_tiny': swin_tiny_patch4_window7_224,\n",
        "         'swin_small': swin_small_patch4_window7_224,\n",
        "         'swin_base': swin_base_patch4_window7_224,\n",
        "         }\n",
        "    print('Model: %s' % d[name].__name__)\n",
        "    return d[name]\n",
        "\n",
        "\n",
        "def seed(seed=0):\n",
        "    import os\n",
        "    import sys\n",
        "    import torch\n",
        "    import numpy as np\n",
        "    import random\n",
        "    sys.setrecursionlimit(100000)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = parser.parse_args('')\n",
        "    args.model = 'vit_base'\n",
        "    args.pretrained_model = 'converted_cifar10-100_500_checkpoint.bin'\n",
        "    seed(args.seed)\n",
        "    args.quant = True\n",
        "    args.pts = True\n",
        "    args.lis = True\n",
        "\n",
        "    device = torch.device(args.device)\n",
        "    cfg = Config(args.pts, args.lis, args.quant_method)\n",
        "    model = str2model(args.model)(pretrained=False, cfg=cfg)\n",
        "    checkpoint = torch.load(args.pretrained_model, map_location=args.device)\n",
        "    model.load_state_dict(checkpoint)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Note: Different models have different strategies of data preprocessing.\n",
        "    # model_type = args.model.split(\"_\")[0]\n",
        "    # if model_type == \"deit\":\n",
        "    #     mean = (0.485, 0.456, 0.406)\n",
        "    #     std = (0.229, 0.224, 0.225)\n",
        "    #     crop_pct = 0.875\n",
        "    # elif model_type == 'vit':\n",
        "    #     mean = (0.5, 0.5, 0.5)\n",
        "    #     std = (0.5, 0.5, 0.5)\n",
        "    #     crop_pct = 0.9\n",
        "    # elif model_type == 'swin':\n",
        "    #     mean = (0.485, 0.456, 0.406)\n",
        "    #     std = (0.229, 0.224, 0.225)\n",
        "    #     crop_pct = 0.9\n",
        "    # else:\n",
        "    #     raise NotImplementedError\n",
        "\n",
        "    # train_transform = build_transform(mean=mean, std=std, crop_pct=crop_pct)\n",
        "    # val_transform = build_transform(mean=mean, std=std, crop_pct=crop_pct)\n",
        "\n",
        "    # # Data\n",
        "    # traindir = os.path.join(args.data, 'train')\n",
        "    # valdir = os.path.join(args.data, 'val')\n",
        "\n",
        "    # val_dataset = datasets.ImageFolder(valdir, val_transform)\n",
        "    # val_loader = torch.utils.data.DataLoader(\n",
        "    #     val_dataset,\n",
        "    #     batch_size=args.val_batchsize,\n",
        "    #     shuffle=False,\n",
        "    #     num_workers=args.num_workers,\n",
        "    #     pin_memory=True,\n",
        "    # )\n",
        "    \n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "    ])\n",
        "\n",
        "    trainset = datasets.CIFAR100(root=\"./data\",\n",
        "                                train=True,\n",
        "                                download=True,\n",
        "                                transform=transform_train)\n",
        "    testset = datasets.CIFAR100(root=\"./data\",\n",
        "                                train=False,\n",
        "                                download=True,\n",
        "                                transform=transform_test)\n",
        "    \n",
        "    train_sampler = RandomSampler(trainset)\n",
        "    test_sampler = SequentialSampler(testset)\n",
        "    train_loader = DataLoader(trainset,\n",
        "                              sampler=train_sampler,\n",
        "                              batch_size=128,\n",
        "                              num_workers=4,\n",
        "                              pin_memory=True)\n",
        "    \n",
        "    test_loader = DataLoader(testset,\n",
        "                             sampler=test_sampler,\n",
        "                             batch_size=args.val_batchsize,\n",
        "                             num_workers=4,\n",
        "                             pin_memory=True)\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    # define loss function (criterion)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    if args.quant:\n",
        "        # train_dataset = datasets.ImageFolder(traindir, train_transform)\n",
        "        # train_loader = torch.utils.data.DataLoader(\n",
        "        #     train_dataset,\n",
        "        #     batch_size=args.calib_batchsize,\n",
        "        #     shuffle=True,\n",
        "        #     num_workers=args.num_workers,\n",
        "        #     pin_memory=True,\n",
        "        #     drop_last=True,\n",
        "        # )\n",
        "        # Get calibration set.\n",
        "        image_list = []\n",
        "        for i, (data, target) in enumerate(train_loader):\n",
        "            if i == args.calib_iter:\n",
        "                break\n",
        "            data = data.to(device)\n",
        "            image_list.append(data)\n",
        "\n",
        "        print(\"Calibrating...\")\n",
        "        model.model_open_calibrate()\n",
        "        with torch.no_grad():\n",
        "            for i, image in enumerate(image_list):\n",
        "                if i == len(image_list)-1:\n",
        "                    # This is used for OMSE method to\n",
        "                    # calculate minimum quantization error\n",
        "                    model.model_open_last_calibrate()\n",
        "                output = model(image)\n",
        "        model.model_close_calibrate()\n",
        "        model.model_quant()\n",
        "\n",
        "    print(\"Validating...\")\n",
        "    val_loss, val_prec1 = validate(\n",
        "        args, test_loader, model, criterion, device\n",
        "    )\n",
        "\n",
        "\n",
        "def validate(args, val_loader, model, criterion, device):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    val_start_time = end = time.time()\n",
        "    for i, (data, target) in enumerate(val_loader):\n",
        "        target = target.to(device)\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1,_ = accuracy(output.data, target, topk=(1,5))\n",
        "        losses.update(loss.data.item(), data.size(0))\n",
        "        top1.update(prec1.data.item(), data.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            print(\n",
        "                \"Test: [{0}/{1}]\\t\"\n",
        "                \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
        "                \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
        "                \"Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\".format(\n",
        "                    i,\n",
        "                    len(val_loader),\n",
        "                    batch_time=batch_time,\n",
        "                    loss=losses,\n",
        "                    top1=top1,\n",
        "                )\n",
        "            )\n",
        "    val_end_time = time.time()\n",
        "    print(\" * Prec@1 {top1.avg:.3f} Time {time:.3f}\".format(\n",
        "        top1=top1, time=val_end_time - val_start_time))\n",
        "\n",
        "    return losses.avg, top1.avg\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "def build_transform(input_size=224, interpolation=\"bicubic\",\n",
        "                    mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),\n",
        "                    crop_pct=0.875):\n",
        "    def _pil_interp(method):\n",
        "        if method == \"bicubic\":\n",
        "            return Image.BICUBIC\n",
        "        elif method == \"lanczos\":\n",
        "            return Image.LANCZOS\n",
        "        elif method == \"hamming\":\n",
        "            return Image.HAMMING\n",
        "        else:\n",
        "            return Image.BILINEAR\n",
        "    resize_im = input_size > 32\n",
        "    t = []\n",
        "    if resize_im:\n",
        "        size = int(math.floor(input_size / crop_pct))\n",
        "        ip = _pil_interp(interpolation)\n",
        "        t.append(\n",
        "            transforms.Resize(\n",
        "                size, interpolation=ip\n",
        "            ),  # to maintain same ratio w.r.t. 224 images\n",
        "        )\n",
        "        t.append(transforms.CenterCrop(input_size))\n",
        "\n",
        "    t.append(transforms.ToTensor())\n",
        "    t.append(transforms.Normalize(mean, std))\n",
        "    return transforms.Compose(t)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210,
          "referenced_widgets": [
            "6d3bdfa8165a42c18130b8b88f6e135f",
            "b559b6298d7c438aa20e44607843ea74",
            "a8aea74c327e4172b7484b12e01ec06c",
            "c8bca9c208294b6b8daf6830d7d678bd",
            "74174fed1b804d5fbf1aa271826f5f09",
            "3db984f5361846e9b9a0b0146b788717",
            "268eb293a26c45ef999d8dd65bd0f3d6",
            "6d4a569402d64105b13d0eafc9908cb5",
            "e885de69d23044ecb229f2be9dbd3a84",
            "cb23bf01c30340cabe9671fcacd58f41",
            "10ceac87431d4f1e867379325d3ef5af"
          ]
        },
        "id": "r1tFG4wVkgNi",
        "outputId": "6b551bc7-2853-40ad-f21b-108db2b98ef9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: vit_base_patch16_224\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d3bdfa8165a42c18130b8b88f6e135f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Calibrating...\n",
            "Validating...\n",
            "Test: [0/100]\tTime 1.421 (1.421)\tLoss 0.3890 (0.3890)\tPrec@1 85.000 (85.000)\t\n",
            " * Prec@1 84.870 Time 88.349\n"
          ]
        }
      ]
    }
  ]
}