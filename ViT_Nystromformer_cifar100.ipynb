{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFJ9Zle-N1B2",
        "outputId": "94f06a21-3cd7-48a3-e2e5-4de06ac1e8ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k70Vxlv9lMRZ",
        "outputId": "4143fa3f-b9e3-4375-f45f-37f2e844665a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ViT-pytorch-Low-rank-Approximation'...\n",
            "remote: Enumerating objects: 190, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 190 (delta 44), reused 27 (delta 27), pack-reused 130\u001b[K\n",
            "Receiving objects: 100% (190/190), 21.31 MiB | 33.06 MiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n",
            "/content/ViT-pytorch-Low-rank-Approximation\n",
            "Collecting ml-collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from ml-collections) (1.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml-collections) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml-collections) (1.15.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections) (0.5.5)\n",
            "Building wheels for collected packages: ml-collections\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=fc584ad456bf7a81e77cbff6650b4d35a7882945811947bbfe67ed88907dc0d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n",
            "Successfully built ml-collections\n",
            "Installing collected packages: ml-collections\n",
            "Successfully installed ml-collections-0.1.1\n",
            "--2022-03-17 09:31:59--  https://docs.google.com/uc?export=download&confirm=t&id=1-AxL45qSt354FadCyK375_60ehXZfCJs\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.204.113, 172.217.204.139, 172.217.204.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.204.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-5g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mrnp9bqbkuen4li1cnl8t3tff98l4ce6/1647509475000/17691537378993098219/*/1-AxL45qSt354FadCyK375_60ehXZfCJs?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-03-17 09:31:59--  https://doc-08-5g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mrnp9bqbkuen4li1cnl8t3tff98l4ce6/1647509475000/17691537378993098219/*/1-AxL45qSt354FadCyK375_60ehXZfCJs?e=download\n",
            "Resolving doc-08-5g-docs.googleusercontent.com (doc-08-5g-docs.googleusercontent.com)... 142.250.97.132, 2607:f8b0:400c:c18::84\n",
            "Connecting to doc-08-5g-docs.googleusercontent.com (doc-08-5g-docs.googleusercontent.com)|142.250.97.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 343302577 (327M) [application/x-zip]\n",
            "Saving to: ‘cifar10-100_500_checkpoint.bin’\n",
            "\n",
            "cifar10-100_500_che 100%[===================>] 327.40M   201MB/s    in 1.6s    \n",
            "\n",
            "2022-03-17 09:32:01 (201 MB/s) - ‘cifar10-100_500_checkpoint.bin’ saved [343302577/343302577]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/YLtrees2/ViT-pytorch-Low-rank-Approximation.git\n",
        "%cd ViT-pytorch-Low-rank-Approximation/\n",
        "!pip install ml-collections\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-AxL45qSt354FadCyK375_60ehXZfCJs' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-AxL45qSt354FadCyK375_60ehXZfCJs\" -O cifar10-100_500_checkpoint.bin && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### In this model, each self-attention is replaced by the Nyströmformer (a Nyström-Based algorithm for approximating Self-Attention).\n",
        "\n",
        "The default version uses 32 landmarks(Nystrom) points to reconstruct the soft-max matrix in self-attention."
      ],
      "metadata": {
        "id": "2VJNSH_B8-Eb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hGKear4S3Q_p"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import logging\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from datetime import timedelta\n",
        "\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from models.modeling_Nystromformer import VisionTransformer, CONFIGS\n",
        "from utils.scheduler import WarmupLinearSchedule, WarmupCosineSchedule\n",
        "from utils.data_utils import get_loader\n",
        "from utils.dist_util import get_world_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Use the following block each time after updating the model.)"
      ],
      "metadata": {
        "id": "nWQXm5W27yj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import sys, importlib\n",
        "#importlib.reload(sys.modules['models.modeling_Nystromformer'])\n",
        "#from models.modeling_Nystromformer import VisionTransformer, CONFIGS"
      ],
      "metadata": {
        "id": "M0pDftVnuikH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "# Required parameters\n",
        "parser.add_argument(\"--name\", default=\"cifar100\",\n",
        "                    help=\"Name of this run. Used for monitoring.\")\n",
        "parser.add_argument(\"--dataset\", choices=[\"cifar10\", \"cifar100\"], default=\"cifar100\",\n",
        "                    help=\"Which downstream task.\")\n",
        "parser.add_argument(\"--model_type\", choices=[\"ViT-B_16\", \"ViT-B_32\", \"ViT-L_16\",\n",
        "                                              \"ViT-L_32\", \"ViT-H_14\", \"R50-ViT-B_16\"],\n",
        "                    default=\"ViT-B_16\",\n",
        "                    help=\"Which variant to use.\")\n",
        "parser.add_argument(\"--pretrained_dir\", type=str, default=\"ViT-B_16.npz\",\n",
        "                    help=\"Where to search for pretrained ViT models.\")\n",
        "parser.add_argument(\"--pretrained_model\", type=str, default=\"/content/drive/MyDrive/cifar100_checkpoint.bin\")\n",
        "parser.add_argument(\"--output_dir\", default=\"output\", type=str,\n",
        "                    help=\"The output directory where checkpoints will be written.\")\n",
        "\n",
        "parser.add_argument(\"--img_size\", default=224, type=int,\n",
        "                    help=\"Resolution size\")\n",
        "parser.add_argument(\"--train_batch_size\", default=512, type=int,\n",
        "                    help=\"Total batch size for training.\")\n",
        "parser.add_argument(\"--eval_batch_size\", default=64, type=int,\n",
        "                    help=\"Total batch size for eval.\")\n",
        "parser.add_argument(\"--eval_every\", default=100, type=int,\n",
        "                    help=\"Run prediction on validation set every so many steps.\"\n",
        "                          \"Will always run one evaluation at the end of training.\")\n",
        "\n",
        "parser.add_argument(\"--learning_rate\", default=3e-2, type=float,\n",
        "                    help=\"The initial learning rate for SGD.\")\n",
        "parser.add_argument(\"--weight_decay\", default=0, type=float,\n",
        "                    help=\"Weight deay if we apply some.\")\n",
        "parser.add_argument(\"--num_steps\", default=10000, type=int,\n",
        "                    help=\"Total number of training epochs to perform.\")\n",
        "parser.add_argument(\"--decay_type\", choices=[\"cosine\", \"linear\"], default=\"cosine\",\n",
        "                    help=\"How to decay the learning rate.\")\n",
        "parser.add_argument(\"--warmup_steps\", default=500, type=int,\n",
        "                    help=\"Step of training to perform learning rate warmup for.\")\n",
        "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n",
        "                    help=\"Max gradient norm.\")\n",
        "\n",
        "parser.add_argument(\"--local_rank\", type=int, default=-1,\n",
        "                    help=\"local_rank for distributed training on gpus\")\n",
        "parser.add_argument('--seed', type=int, default=42,\n",
        "                    help=\"random seed for initialization\")\n",
        "parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n",
        "                    help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
        "parser.add_argument('--fp16', action='store_true',\n",
        "                    help=\"Whether to use 16-bit float precision instead of 32-bit\")\n",
        "parser.add_argument('--fp16_opt_level', type=str, default='O2',\n",
        "                    help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
        "                          \"See details at https://nvidia.github.io/apex/amp.html\")\n",
        "parser.add_argument('--loss_scale', type=float, default=0,\n",
        "                    help=\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"\n",
        "                          \"0 (default value): dynamic loss scaling.\\n\"\n",
        "                          \"Positive power of 2: static loss scaling value.\\n\")\n",
        "args = parser.parse_args(\"\")\n",
        "\n",
        "# Setup CUDA, GPU & distributed training\n",
        "if args.local_rank == -1:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    args.n_gpu = torch.cuda.device_count()\n",
        "else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "    torch.cuda.set_device(args.local_rank)\n",
        "    device = torch.device(\"cuda\", args.local_rank)\n",
        "    torch.distributed.init_process_group(backend='nccl',\n",
        "                                          timeout=timedelta(minutes=60))\n",
        "    args.n_gpu = 1\n",
        "\n",
        "args.name = 'cifar100'\n",
        "args.device = device"
      ],
      "metadata": {
        "id": "2t5UUX-qR_lO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = CONFIGS[args.model_type]\n",
        "num_classes = 10 if args.dataset == \"cifar10\" else 100\n",
        "model = VisionTransformer(config, args.img_size, zero_head=True, num_classes=num_classes)\n",
        "model.load_state_dict(torch.load(args.pretrained_model, map_location=torch.device(args.device)))\n",
        "model.to(args.device)\n",
        "train_loader, test_loader = get_loader(args)\n"
      ],
      "metadata": {
        "id": "w9chZMfcSYaW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "ad1157820d7e44c3a2eabdf93a623a28",
            "ba03c0ff3b414c6b8b2f171e0b14acae",
            "e3959ee0def24a70b6402caff1a66e4b",
            "c8860c022f624468b11ff81a4a6a6005",
            "e771ab3fd9634fe4bc01fed65012bc05",
            "c5ea0bd0802a47dbba86e13ebcccc827",
            "3fd85ed73e6f4646824d124c8bf74223",
            "9619da1e6af34e93bab99fd4375db798",
            "07c0d36a8fed4aa38c4f4064cdebb6c6",
            "6097160468c04931ba6906ab01d6ca0d",
            "f970ae69dcb24b8bb9d1c16c99f3855e"
          ]
        },
        "outputId": "d43a506d-7eab-4d5b-d5dc-05650a1de463"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad1157820d7e44c3a2eabdf93a623a28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "def test(model, test_loader):\n",
        "  model.eval()\n",
        "  all_preds, all_label = [], []\n",
        "  epoch_iterator = tqdm(test_loader,\n",
        "                        desc=\"Validating... (loss=X.X)\",\n",
        "                        bar_format=\"{l_bar}{r_bar}\",\n",
        "                        dynamic_ncols=True,\n",
        "                        disable=args.local_rank not in [-1, 0])\n",
        "  loss_fct = torch.nn.CrossEntropyLoss()\n",
        "  #max_itr = 10\n",
        "  for step, batch in enumerate(epoch_iterator):\n",
        "      #if step >= max_itr:\n",
        "      #  break\n",
        "      batch = tuple(t.to(args.device) for t in batch)\n",
        "      x, y = batch\n",
        "      with torch.no_grad():\n",
        "          logits = model(x)[0]\n",
        "\n",
        "          eval_loss = loss_fct(logits, y)\n",
        "          # eval_losses.update(eval_loss.item())\n",
        "\n",
        "          preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "      if len(all_preds) == 0:\n",
        "          all_preds.append(preds.detach().cpu().numpy())\n",
        "          all_label.append(y.detach().cpu().numpy())\n",
        "      else:\n",
        "          all_preds[0] = np.append(\n",
        "              all_preds[0], preds.detach().cpu().numpy(), axis=0\n",
        "          )\n",
        "          all_label[0] = np.append(\n",
        "              all_label[0], y.detach().cpu().numpy(), axis=0\n",
        "          )\n",
        "      # epoch_iterator.set_description(\"Validating... (loss=%2.5f)\" % eval_losses.val)\n",
        "\n",
        "  all_preds, all_label = all_preds[0], all_label[0]\n",
        "  accuracy = simple_accuracy(all_preds, all_label)\n",
        "  print(\"Valid Accuracy: %2.5f\" % accuracy)"
      ],
      "metadata": {
        "id": "3208CvASUeR3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVlGinkOaCps",
        "outputId": "26536a18-eccb-4516-f616-c39465fcdd6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating... (loss=X.X): 100%|| 157/157 [01:01<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Accuracy: 0.50310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_size = 0\n",
        "for param in model.parameters():\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "buffer_size = 0\n",
        "for buffer in model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "size_all_mb"
      ],
      "metadata": {
        "id": "DQ6khhsEmEXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8577f18-a0f3-48eb-fe92-ed9e70be4cbd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327.58924865722656"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we also check versions which use 24 and 64 landmarks respectively."
      ],
      "metadata": {
        "id": "AIcYI7Hl9wfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, importlib\n",
        "importlib.reload(sys.modules['models.modeling_Nystromformer'])\n",
        "from models.modeling_Nystromformer_24landmarks import VisionTransformer, CONFIGS\n",
        "\n",
        "config = CONFIGS[args.model_type]\n",
        "num_classes = 10 if args.dataset == \"cifar10\" else 100\n",
        "model24 = VisionTransformer(config, args.img_size, zero_head=True, num_classes=num_classes)\n",
        "model24.load_state_dict(torch.load(args.pretrained_model, map_location=torch.device(args.device)))\n",
        "model24.to(args.device)\n",
        "train_loader, test_loader = get_loader(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_SgjMGV-EwD",
        "outputId": "4cf7a866-75da-412f-ba28-e4e74f90d342"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model24, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWzyESrZ-6-Z",
        "outputId": "2b8a1a1d-e7c6-46a4-cf23-46b8778bb86e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating... (loss=X.X): 100%|| 157/157 [01:00<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Accuracy: 0.38510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, importlib\n",
        "importlib.reload(sys.modules['models.modeling_Nystromformer'])\n",
        "\n",
        "from models.modeling_Nystromformer_64landmarks import VisionTransformer, CONFIGS\n",
        "\n",
        "config = CONFIGS[args.model_type]\n",
        "num_classes = 10 if args.dataset == \"cifar10\" else 100\n",
        "model64 = VisionTransformer(config, args.img_size, zero_head=True, num_classes=num_classes)\n",
        "model64.load_state_dict(torch.load(args.pretrained_model, map_location=torch.device(args.device)))\n",
        "model64.to(args.device)\n",
        "train_loader, test_loader = get_loader(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBIxIYSU-94C",
        "outputId": "9bfb814b-4068-4482-8856-179396f497a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model64, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgWyGPzk_S0t",
        "outputId": "fa4cee02-4044-4327-ad53-9432436135ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating... (loss=X.X): 100%|| 157/157 [01:04<00:00,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Accuracy: 0.74010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently we use 2 iterations of iterative inverse for each self-attention and use the exact coefficient computatio (instead of the original implementation to compute coefficient of Z_0). It is also possible to further try other values combining with the choices of the number of landmarks."
      ],
      "metadata": {
        "id": "ifrNcwqV_Uf_"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ViT_Nystromformer_cifar100.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad1157820d7e44c3a2eabdf93a623a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba03c0ff3b414c6b8b2f171e0b14acae",
              "IPY_MODEL_e3959ee0def24a70b6402caff1a66e4b",
              "IPY_MODEL_c8860c022f624468b11ff81a4a6a6005"
            ],
            "layout": "IPY_MODEL_e771ab3fd9634fe4bc01fed65012bc05"
          }
        },
        "ba03c0ff3b414c6b8b2f171e0b14acae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ea0bd0802a47dbba86e13ebcccc827",
            "placeholder": "​",
            "style": "IPY_MODEL_3fd85ed73e6f4646824d124c8bf74223",
            "value": ""
          }
        },
        "e3959ee0def24a70b6402caff1a66e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9619da1e6af34e93bab99fd4375db798",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07c0d36a8fed4aa38c4f4064cdebb6c6",
            "value": 169001437
          }
        },
        "c8860c022f624468b11ff81a4a6a6005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6097160468c04931ba6906ab01d6ca0d",
            "placeholder": "​",
            "style": "IPY_MODEL_f970ae69dcb24b8bb9d1c16c99f3855e",
            "value": " 169001984/? [00:02&lt;00:00, 70012033.66it/s]"
          }
        },
        "e771ab3fd9634fe4bc01fed65012bc05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ea0bd0802a47dbba86e13ebcccc827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd85ed73e6f4646824d124c8bf74223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9619da1e6af34e93bab99fd4375db798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c0d36a8fed4aa38c4f4064cdebb6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6097160468c04931ba6906ab01d6ca0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f970ae69dcb24b8bb9d1c16c99f3855e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}